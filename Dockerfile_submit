FROM spark-2

# Set default environment variables. These can also be set at the command line when invoking /bin/spark-submit
# ENV MASTER_CONTAINER_NAME=spark-master-local
# ENV SPARK_EXECUTOR_MEMORY=6G
# ENV SPARK_EXECUTOR_CORES=3
ENV HIVE_HOME=/opt/hive
ENV HUDI_HOME=/opt/hudi
ENV PYTHONPATH=$SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.10.9.5-src.zip:$PYTHONPATH
ENV PATH=$SPARK_HOME/bin:$SPARK_HOME/python:$HIVE_HOME/bin:$PATH
ENV CLASSPATH=$CLASSPATH:$HIVE_HOME/libs/mysql-connector-java-8.0.14.jar
ENV PATH=$PATH:$HIVE_HOME/bin


RUN  mkdir -p "$HIVE_HOME" "$HUDI_HOME" 
RUN wget -qO - https://dlcdn.apache.org/hudi/0.13.1/hudi-0.13.1.src.tgz | tar -xz -C $HUDI_HOME --strip-components=1 
RUN wget -qO - https://dlcdn.apache.org/hive/hive-3.1.3/apache-hive-3.1.3-bin.tar.gz | tar -xz -C $HIVE_HOME --strip-components=1 
#Run jupyter notebook locally
# Run schematool for mysql
COPY data/hive-site.xml $HIVE_HOME/conf/
COPY ./resources/log4j.properties $SPARK_HOME/conf/

# Exclude Log4j1 from Hive and Hadoop dependencies
RUN rm $HIVE_HOME/lib/log4j-slf4j-impl-*.jar
RUN rm $HADOOP_HOME/share/hadoop/common/lib/slf4j-log4j12-*.jar

COPY apps/mysql-connector-java-8.0.14.jar $HIVE_HOME/lib/
COPY apps/mysql-connector-java-8.0.14.jar $SPARK_HOME/jars/

# RUN $HIVE_HOME/bin/schematool -dbType mysql -initSchema --verbose


ENV PYSPARK_DRIVER_PYTHON='jupyter'
ENV PYSPARK_DRIVER_PYTHON_OPTS='notebook --no-browser --port=8889 --allow-root --ip=0.0.0.0 --NotebookApp.token='
# Install libraries
COPY ./resources/requirements.txt .
RUN update-alternatives --install /usr/bin/pip pip /usr/bin/pip3 1
RUN pip install pyspark
RUN PYSPARK_RELEASE_MIRROR=http://mirror.apache-kr.org PYSPARK_HADOOP_VERSION=2 pip install pyspark -v
RUN pip install -r requirements.txt

# Copy examples python files into container
COPY ./examples/ /home/examples/

# COPY ./resources/spark-defaults.conf $SPARK_HOME/conf/
EXPOSE 4040 8888 18080 8889 10000 10001

WORKDIR $SPARK_HOME
